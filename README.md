# Project03 â€“ Calculus in Data Science

## ğŸ“Œ Introduction
This project demonstrates how **Calculus** is applied in Data Science, focusing on **Gradient Descent** â€“ an optimization technique to minimize errors in machine learning models.  
We compare our **manual gradient descent implementation** with **Scikit-learnâ€™s LinearRegression**.

---

## âš™ï¸ Steps
1. Import dataset (`sample_data.csv`)
2. Implement Gradient Descent manually
3. Visualize cost function reduction
4. Compare results with Scikit-learn

---

## ğŸ“Š Results
- Gradient Descent successfully minimized cost  
- Sklearn coefficients matched our implementation closely  
- Plots show convergence of the model  

---

## ğŸ“‚ Repository Structure
- **data/** â†’ Dataset  
- **notebooks/** â†’ Jupyter notebook with code & explanations  
- **src/** â†’ Python script (clean implementation)  
- **results/** â†’ Graph outputs  
- **requirements.txt** â†’ Dependencies  

---

## ğŸš€ How to Run
```bash
pip install -r requirements.txt
jupyter notebook notebooks/Project03_Calculus.ipynb
